{
    "test_deepseek2_hf2mcore_tp1pp4ep8": [
        {
            "param": {
                "model-type":"GPT",
                "load-model-type":"hf",
                "save-model-type":"mg",
                "target-tensor-parallel-size": "1",
                "target-pipeline-parallel-size": "4",
                "target-expert-parallel-size": "8",
                "load-dir":"/data/ci/models/deepseek-v2/hf/deepseek2_hf",
                "save-dir":"/data/ci/cache/deepseek2_tp1pp4ep8",
                "use-mcore-models": null,
                "moe-grouped-gemm": null,
                "model-type-hf": "deepseek2",
                "params-dtype": "bf16",
                "tokenizer-model":"/data/ci/deepseek2/hf/deepseek2_hf",
                "spec":"mindspeed_llm.tasks.models.spec.deepseek_spec layer_spec"
            }
        }
    ],

    "test_deepseek2_mcore2hf_tp1pp4ep8": [
        {
            "param": {
                "model-type":"GPT",
                "load-model-type":"mg",
                "save-model-type": "hf",
                "target-tensor-parallel-size": "1",
                "target-pipeline-parallel-size": "1",
                "target-expert-parallel-size": "1",
                "save-dir":"/data/ci/models/deepseek-v2/hf/deepseek2_hf",
                "load-dir":"/data/ci/models/deepseek2/mg/deepseek2-l8-t1p4e8-gemm_new",
                "use-mcore-models": null,
                "moe-grouped-gemm": null,
                "model-type-hf": "deepseek2",
                "params-dtype": "bf16",
                "spec":"mindspeed_llm.tasks.models.spec.deepseek_spec layer_spec"
            }
        }
    ],

    "test_llama2_hf2mcore_orm_pp2vpp2":[
        {
            "param":{
                "model-type":"GPT",
                "load-model-type":"hf",
                "save-model-type":"mg",
                "params-dtype":"bf16",
                "target-tensor-parallel-size": "1",
                "target-pipeline-parallel-size": "2",
                "num-layers-per-virtual-pipeline-stage": "2",
                "load-dir":"/data/ci/models/llama2/hf/llama-2-7b-layers8-rm-hf/",
                "save-dir":"/data/ci/cache/llama-2-7b-layers8-rm-mcore_pp2vpp2_test/",
                "tokenizer-model":"/data/ci/models/llama2/hf/llama-2-7b-hf/tokenizer.model",
                "use-mcore-models": null,
                "model-type-hf": "llama2",
                "orm": null
            }
        }
    ]
}





