# Seq1F1B 流水线并行

## 背景与挑战

训练大型语言模型（LLM）在很大程度上依赖于分布式训练策略，其中流水线并行性（PP）起着至关重要的作用。随着训练序列扩展到32K甚至128K令牌，当前的PP方法面临着严重的瓶颈，包括大量的流水线气泡和高显存占用，极大地阻碍了训练吞吐量和模型可扩展性。[Seq1F1B](https://arxiv.org/abs/2406.03488 'Seq1F1B Paper')一种序列级一前一后（1F1B）PP方法，专为在长序列上训练LLM而设计，具有高训练吞吐量和显存效率。它使用一种计算策略来适当地划分序列，显著减少了流水线气泡和显存占用。

## 原理

![alt text](../../../sources/images/seq1f1b/seq1f1b_img.png)

**预热阶段-累积前向**：该阶段只进行前向计算。使用序列划分的方法，将原始序列划分成$s$个子序列，依次读入并进行前向计算。因此，Seq1F1B中每个子序列对应的前向计算时间和动态显存降低至1F1B的$1/s$。

**稳定阶段-交替前向和后向**：该阶段交替进行前向后向计算。Seq1F1B中每个子序列对应的前向和后向计算时间均降低至1F1B的$1/s$。当流水线并行阶段数量为$p$时，Device1在进行第一次反向之前，累积的前向数量峰值为$s+p-1$。

**冷却阶段-结束后向**：该阶段进行剩余的后向计算，结束后同步更新优化器和模型参数。

**总体来看**：Seq1F1B的收益如下

- Device1的动态显存峰值降为1F1B的 $\frac{s+p-1}{sp} = \frac{1}{s}+\frac{1}{p}-\frac{1}{sp}$, 但KV缓存会增加一些额外的显存占用。

- 整体空泡降低至1F1B的 $\frac{1}{s}$ 

因此，$s$和$p$越大，Seq1F1B的显存收益越明显。此外，我们实现了支持重计算（Recompute）特性的Seq1F1B，可以兼容现有的全量重计算和选择重计算特性，进一步降低动态显存占用。

## 使用方法

### 参数详解
在 msrun 启动bash 脚本中增加如下参数来使用Seq1F1B:

- 使用参数 **--seq1f1b-splits [int]** 控制seq1f1b中序列拆分后子序列的数量$s$，推荐使用4，如果设置大于1，则使用Seq1F1B，否则使用默认使用Megatron 1F1B。

- 使用参数 **--seq1f1b-balance-method [string]** 平衡子序列的方法，可选项为['average', 'uniform_comp']，默认使用'average'。'average'方法是根据序列长度进行均匀切分，平衡每个子序列的token数目；'uniform_comp'方法是根据序列的计算量进行切分，平衡每个子序列的FLOPs。
- 使用参数 **--reset-attention-mask** 进行多样本pack模式预训练/微调，此时**不能使用参数--no-pad-to-seq-lengths**。

## 使用效果分析及验证

### 性能及显存理论分析
| PP\评价指标        | 空泡 | 动态显存 | 
| ----------| ------------ | ----------------- |
| 1F1B      | $(p-1)(F+B)$      |      $pM$          |
| Seq1F1B   | $(p-1)\frac{(F+B)}{s}$    |  $\frac{s+p-1}{s}M$+kv_cache  |

其中，$p$为流水线并行阶段数量，$s$为序列切分数量，$F$和$B$为Model Chunk进行一次前向和后向的时间，$M$为Model Chunk进行一次前向过程所累积的动态显存。

### 性能及显存实验验证

实验中seq_len=16k, $s$=4, 且均开启同样的重计算。1F1B<sup>R</sup>和Seq1F1B<sup>R</sup> 表示开启重计算特性后的1F1B和Seq1F1B。

#### Qwen3-4b 预训练

| Qwen3-4b (PP=8,TP=1)  | 性能 ms/iter | Device1显存 MB |
| ----------| ------------ | -------------| 
| 1F1B<sup>R</sup>      |  11711 ($ \times 1.00$)     |  46214  |
| Seq1F1B<sup>R</sup>  |  10257 ($ \times 1.14$)  |  26942  |

#### DeepSeek3 微调

| DeepSeek3 单机8卡 (PP=4,TP=2)  | 性能 ms/iter | Device1显存 MB |
| ----------| ------------ | ----------------- |
| 1F1B<sup>R</sup>       | 16532 ($ \times 1.00$)      |   31122    |
| Seq1F1B<sup>R</sup>   | 15002 ($ \times 1.10$)   |   24539    |

## 注意

- 当前seq1f1b仅支持--micro-batch-size为1
- 当前seq1f1b仅支持多样本pack模式的预训练/微调
- 由于序列切分会带来算子下发次数为原来的$s$倍，实验发现，seq1f1b在子序列长度不小于4k时能明显看到性能收益。